{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graphlib import TopologicalSorter\n",
    "import sklearn.linear_model as lm\n",
    "\n",
    "class PipelineStructure:\n",
    "    def __init__(self):\n",
    "        self.nodes = set()\n",
    "        self.edges = set()\n",
    "        self.components = {'start': None}\n",
    "        self.current_node = 'start'\n",
    "\n",
    "    def update(self, node, component):\n",
    "        self.add_node(node, component)\n",
    "        self.add_edge(self.current_node, node)\n",
    "        self.current_node = node\n",
    "\n",
    "    def add_node(self, node, component):\n",
    "        self.nodes.add(node)\n",
    "        self.components[node] = component\n",
    "\n",
    "    def add_edge(self, sender, reciever):\n",
    "        self.edges.add((sender, reciever))\n",
    "\n",
    "    def make_graph(self):\n",
    "        self.graph = dict()\n",
    "        for edge in self.edges:\n",
    "            self.graph.setdefault(edge[1], set()).add(edge[0])\n",
    "\n",
    "    def __call__(self, feature_matrix: np.ndarray, response_vector: np.ndarray):\n",
    "        self.outputs = dict()\n",
    "        ts = TopologicalSorter(self.graph)\n",
    "        for node in ts.static_order():\n",
    "\n",
    "            if node == 'start':\n",
    "                self.outputs[node] = (np.arange(feature_matrix.shape[1]), np.array([]))\n",
    "\n",
    "            elif isinstance(self.components[node], (FeatureSelection, OutlierDetection)):\n",
    "                layer = self.components[node]\n",
    "                parants = list(self.graph[node])\n",
    "                assert len(parants) == 1\n",
    "                selected_features, detected_outliers = self.outputs[parants[0]]\n",
    "\n",
    "                if isinstance(layer, FeatureSelection):\n",
    "                    selected_features = layer.select_features(\n",
    "                        feature_matrix, response_vector, selected_features, detected_outliers)\n",
    "\n",
    "                else:\n",
    "                    detected_outliers = layer.detect_outliers(\n",
    "                        feature_matrix, response_vector, selected_features, detected_outliers)\n",
    "                self.outputs[node] = (selected_features, detected_outliers)\n",
    "\n",
    "            elif isinstance(self.components[node], MissingImputation):\n",
    "                parants = list(self.graph[node])\n",
    "                assert len(parants) == 1\n",
    "                selected_features, detected_outliers = self.outputs[parants[0]]\n",
    "                response_vector = self.components[node].impute_missing(\n",
    "                    feature_matrix, response_vector)\n",
    "                self.outputs[node] = (selected_features, detected_outliers)\n",
    "\n",
    "            elif isinstance(self.components[node], IndexesOperator):\n",
    "                layer = self.components[node]\n",
    "                parants = list(self.graph[node])\n",
    "                selected_features_list = []\n",
    "                detected_outliers_list = []\n",
    "                for parant in parants:\n",
    "                    selected_features, detected_outliers = self.outputs[parant]\n",
    "                    selected_features_list.append(selected_features)\n",
    "                    detected_outliers_list.append(detected_outliers)\n",
    "                if isinstance(layer, Union):\n",
    "                    selected_features = layer.union(*selected_features_list)\n",
    "                    detected_outliers = layer.union(*detected_outliers_list)\n",
    "                elif isinstance(layer, Intersection):\n",
    "                    selected_features = layer.intersection(*selected_features_list)\n",
    "                    detected_outliers = layer.intersection(*detected_outliers_list)\n",
    "                else:\n",
    "                    raise TypeError('Input must be Union or Intersection')\n",
    "                self.outputs[node] = (selected_features, detected_outliers)\n",
    "\n",
    "            elif isinstance(self.components[node], (DeleteOutliers, ExtractFeatures)):\n",
    "                parents = list(self.graph[node])\n",
    "                assert len(parents) == 1\n",
    "                self.outputs[node] = self.outputs[parants[0]]\n",
    "\n",
    "            elif node == 'end':\n",
    "                parants = list(self.graph[node])\n",
    "                assert len(parants) == 1\n",
    "                selected_features, _ = self.outputs[parants[0]]\n",
    "                return selected_features\n",
    "\n",
    "    def inference(self, feature_matrix):\n",
    "        self.outputs = dict()\n",
    "        ts = TopologicalSorter(self.graph)\n",
    "        # ts.prepare()\n",
    "        for node in ts.static_order():\n",
    "\n",
    "            if node == 'start':\n",
    "                self.outputs[node] = (np.arange(feature_matrix.shape[1]), np.array([]))\n",
    "\n",
    "            elif isinstance(self.components[node], (FeatureSelection, OutlierDetection)):\n",
    "                layer = self.components[node]\n",
    "                parants = list(self.graph[node])\n",
    "                assert len(parants) == 1\n",
    "                selected_features, detected_outliers = self.outputs[parants[0]]\n",
    "\n",
    "                if isinstance(layer, FeatureSelection):\n",
    "                    selected_features = layer.select_features(\n",
    "                        feature_matrix, response_vector, selected_features, detected_outliers)\n",
    "\n",
    "                else:\n",
    "                    detected_outliers = layer.detect_outliers(\n",
    "                        feature_matrix, response_vector, selected_features, detected_outliers)\n",
    "                self.outputs[node] = (selected_features, detected_outliers)\n",
    "\n",
    "            elif isinstance(self.components[node], MissingImputation):\n",
    "                parants = list(self.graph[node])\n",
    "                assert len(parants) == 1\n",
    "                selected_features, detected_outliers = self.outputs[parants[0]]\n",
    "                response_vector = self.components[node].impute_missing(\n",
    "                    feature_matrix, response_vector)\n",
    "                self.outputs[node] = (selected_features, detected_outliers)\n",
    "\n",
    "            elif isinstance(self.components[node], IndexesOperator):\n",
    "                layer = self.components[node]\n",
    "                parants = list(self.graph[node])\n",
    "                selected_features_list = []\n",
    "                detected_outliers_list = []\n",
    "                for parant in parants:\n",
    "                    selected_features, detected_outliers = self.outputs[parant]\n",
    "                    selected_features_list.append(selected_features)\n",
    "                    detected_outliers_list.append(detected_outliers)\n",
    "                if isinstance(layer, Union):\n",
    "                    selected_features = layer.union(*selected_features_list)\n",
    "                    detected_outliers = layer.union(*detected_outliers_list)\n",
    "                elif isinstance(layer, Intersection):\n",
    "                    selected_features = layer.intersection(*selected_features_list)\n",
    "                    detected_outliers = layer.intersection(*detected_outliers_list)\n",
    "                else:\n",
    "                    raise TypeError('Input must be Union or Intersection')\n",
    "                self.outputs[node] = (selected_features, detected_outliers)\n",
    "\n",
    "            elif isinstance(self.components[node], (DeleteOutliers, ExtractFeatures)):\n",
    "                parents = list(self.graph[node])\n",
    "                assert len(parents) == 1\n",
    "                self.outputs[node] = self.outputs[parants[0]]\n",
    "\n",
    "            elif node == 'end':\n",
    "                parants = list(self.graph[node])\n",
    "                assert len(parants) == 1\n",
    "                selected_features, _ = self.outputs[parants[0]]\n",
    "                return selected_features\n",
    "\n",
    "\n",
    "    def __or__(self, other):\n",
    "        if isinstance(other, PipelineStructure):\n",
    "            pl = PipelineStructure()\n",
    "            pl.nodes = self.nodes | other.nodes\n",
    "            pl.edges = self.edges | other.edges\n",
    "            pl.components = {**self.components, **other.components}\n",
    "            if self.nodes >= other.nodes:\n",
    "                pl.current_node = self.current_node\n",
    "            else:\n",
    "                pl.current_node = other.current_node\n",
    "            return pl\n",
    "        else:\n",
    "            raise TypeError('Input must be PipelineStructure')\n",
    "\n",
    "\n",
    "class FeatureMatrix:\n",
    "    def __init__(self, pl_structure):\n",
    "        self.pl_structure = pl_structure\n",
    "\n",
    "class ResponseVector:\n",
    "    def __init__(self, pl_structure):\n",
    "        self.pl_structure = pl_structure\n",
    "\n",
    "class SelectedFeatures:\n",
    "    def __init__(self, pl_structure):\n",
    "        self.pl_structure = pl_structure\n",
    "\n",
    "class DetectedOutliers:\n",
    "    def __init__(self, pl_structure):\n",
    "        self.pl_structure = pl_structure\n",
    "\n",
    "\n",
    "class FeatureSelection:\n",
    "    instance_counter = dict()\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        parameters: float | list[float],\n",
    "        candidates: list[float] | list[list[float]]):\n",
    "        self.parameters = parameters\n",
    "        self.candidates = candidates\n",
    "        FeatureSelection.instance_counter.setdefault(name, 0)\n",
    "        self.name = f'{name}_{FeatureSelection.instance_counter[name]}'\n",
    "        FeatureSelection.instance_counter[name] += 1\n",
    "\n",
    "    def __call__(self, feature_matrix: FeatureMatrix, response_vector: ResponseVector) -> SelectedFeatures:\n",
    "        pl_structure = feature_matrix.pl_structure | response_vector.pl_structure\n",
    "        pl_structure.update(self.name, self)\n",
    "        return SelectedFeatures(pl_structure)\n",
    "\n",
    "    def select_features(\n",
    "        self, feature_matrix: np.ndarray, response_vector: np.ndarray,\n",
    "        selected_features: np.ndarray, detected_outliers: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def perform_si(\n",
    "        self,\n",
    "        a: np.ndarray,\n",
    "        b: np.ndarray,\n",
    "        z: float,\n",
    "        feature_matrix: np.ndarray,\n",
    "        selected_features: np.ndarray,\n",
    "        detected_outliers: np.ndarray,\n",
    "        l: float,\n",
    "        u: float,\n",
    "        ) -> (np.ndarray, np.ndarray, float, float):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class OutlierDetection:\n",
    "    instance_counter = dict()\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        parameters: float | list[float],\n",
    "        candidates: list[float] | list[list[float]]):\n",
    "        self.parameters = parameters\n",
    "        self.candidates = candidates\n",
    "        OutlierDetection.instance_counter.setdefault(name, 0)\n",
    "        self.name = f'{name}_{OutlierDetection.instance_counter[name]}'\n",
    "        OutlierDetection.instance_counter[name] += 1\n",
    "\n",
    "    def __call__(self, feature_matrix: FeatureMatrix, response_vector: ResponseVector) -> DetectedOutliers:\n",
    "        pl_structure = feature_matrix.pl_structure | response_vector.pl_structure\n",
    "        pl_structure.update(self.name, self)\n",
    "        return DetectedOutliers(pl_structure)\n",
    "\n",
    "    def detect_outliers(\n",
    "        self, feature_matrix: np.ndarray, response_vector: np.ndarray,\n",
    "        selected_features: np.ndarray, detected_outliers: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def perform_si(\n",
    "        self,\n",
    "        a: np.ndarray,\n",
    "        b: np.ndarray,\n",
    "        z: float,\n",
    "        feature_matrix: np.ndarray,\n",
    "        selected_features: np.ndarray,\n",
    "        detected_outliers: np.ndarray,\n",
    "        l: float,\n",
    "        u: float,\n",
    "        ) -> (np.ndarray, np.ndarray, float, float):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class MissingImputation:\n",
    "    instance_counter = dict()\n",
    "\n",
    "    def __init__(self, name: str):\n",
    "        MissingImputation.instance_counter.setdefault(name, 0)\n",
    "        self.name = f'{name}_{MissingImputation.instance_counter[name]}'\n",
    "        MissingImputation.instance_counter[name] += 1\n",
    "\n",
    "    def __call__(self, feature_matrix: FeatureMatrix, response_vector: ResponseVector) -> ResponseVector:\n",
    "        pl_structure = feature_matrix.pl_structure | response_vector.pl_structure\n",
    "        pl_structure.update(self.name, self)\n",
    "        return ResponseVector(pl_structure)\n",
    "\n",
    "    def impute_missing(self, feature_matrix: np.ndarray, response_vector: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def compute_covariance(\n",
    "        self,\n",
    "        feature_matrix: np.ndarray,\n",
    "        response_vector: np.ndarray,\n",
    "        variance: float,\n",
    "        ) -> (np.ndarray, np.ndarray, np.ndarray):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class IndexesOperator:\n",
    "    instance_counter = dict()\n",
    "\n",
    "    def __init__(self, name: str):\n",
    "        IndexesOperator.instance_counter.setdefault(name, 0)\n",
    "        self.name = f'{name}_{IndexesOperator.instance_counter[name]}'\n",
    "        IndexesOperator.instance_counter[name] += 1\n",
    "\n",
    "    def __call__(self, *inputs: tuple[SelectedFeatures] | tuple[DetectedOutliers]) -> SelectedFeatures | DetectedOutliers:\n",
    "        pl_structure = inputs[0].pl_structure\n",
    "        pl_structure.update(self.name, self)\n",
    "        input_type = type(inputs[0])\n",
    "        if len(inputs) > 1:\n",
    "            for input in inputs[1:]:\n",
    "                if input_type != type(input):\n",
    "                    raise TypeError('Inputs must be same type')\n",
    "                input.pl_structure.update(self.name, self)\n",
    "                pl_structure = pl_structure | input.pl_structure\n",
    "        if isinstance(inputs[0], SelectedFeatures):\n",
    "            self.mode = 'selected_features'\n",
    "            return SelectedFeatures(pl_structure)\n",
    "        elif isinstance(inputs[0], DetectedOutliers):\n",
    "            self.mode = 'detected_outliers'\n",
    "            return DetectedOutliers(pl_structure)\n",
    "        else:\n",
    "            raise TypeError('Inputs must be SelectedFeatures or DetectedOutliers')\n",
    "\n",
    "\n",
    "class DeleteOutliers:\n",
    "    counter = 0\n",
    "\n",
    "    def __init__(self, name='delete'):\n",
    "        self.name = f'{name}_{DeleteOutliers.counter}'\n",
    "        DeleteOutliers.counter += 1\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        feature_matrix: FeatureMatrix,\n",
    "        response_vector: ResponseVector,\n",
    "        detected_outliers: DetectedOutliers\n",
    "        ) -> (FeatureMatrix, ResponseVector):\n",
    "        pl_structure = feature_matrix.pl_structure | response_vector.pl_structure | detected_outliers.pl_structure\n",
    "        pl_structure.update(self.name, self)\n",
    "        return FeatureMatrix(pl_structure), ResponseVector(pl_structure)\n",
    "\n",
    "    def delete_outliers(\n",
    "        self,\n",
    "        feature_matrix: np.ndarray,\n",
    "        response_vector: np.ndarray,\n",
    "        detected_outliers: np.ndarray\n",
    "        ) -> (np.ndarray, np.ndarray):\n",
    "        non_outliers = np.delete(np.arange(feature_matrix.shape[0]), detected_outliers)\n",
    "        return feature_matrix[non_outliers, :], response_vector[non_outliers]\n",
    "\n",
    "class ExtractFeatures:\n",
    "    counter = 0\n",
    "\n",
    "    def __init__(self, name='extract'):\n",
    "        self.name = f'{name}_{ExtractFeatures.counter}'\n",
    "        ExtractFeatures.counter += 1\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        feature_matrix: FeatureMatrix,\n",
    "        selected_features: SelectedFeatures\n",
    "        ) -> FeatureMatrix:\n",
    "        pl_structure = feature_matrix.pl_structure | selected_features.pl_structure\n",
    "        pl_structure.update(self.name, self)\n",
    "        return FeatureMatrix(pl_structure)\n",
    "\n",
    "    def extract_features(\n",
    "        self,\n",
    "        feature_matrix: np.ndarray,\n",
    "        selected_features: np.ndarray\n",
    "        ) -> np.ndarray:\n",
    "        return feature_matrix[:, selected_features]\n",
    "\n",
    "\n",
    "class Union(IndexesOperator):\n",
    "    def __init__(self, name='union'):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def union(self, *inputs: tuple[np.ndarray]) -> np.ndarray:\n",
    "        if len(inputs) == 1:\n",
    "            return inputs[0]\n",
    "        else:\n",
    "            temp_set = set(inputs[0].tolist())\n",
    "            for input in inputs[1:]:\n",
    "                temp_set = temp_set | set(input.tolist())\n",
    "            return np.array(list(temp_set))\n",
    "\n",
    "class Intersection(IndexesOperator):\n",
    "    def __init__(self, name='intersection'):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def intersection(self, *inputs: tuple[np.ndarray]) -> np.ndarray:\n",
    "        if len(inputs) == 1:\n",
    "            return inputs[0]\n",
    "        else:\n",
    "            temp_set = set(inputs[0].tolist())\n",
    "            for input in inputs[1:]:\n",
    "                temp_set = temp_set & set(input.tolist())\n",
    "            return np.array(list(temp_set))\n",
    "\n",
    "\n",
    "class MeanValueImputation(MissingImputation):\n",
    "    def __init__(self, name='mean_value_imputation'):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def impute_missing(self, feature_matrix: np.ndarray, response_vector: np.ndarray) -> np.ndarray:\n",
    "        _, y = feature_matrix, response_vector\n",
    "        n = y.shape[0]\n",
    "\n",
    "        # location of missing value\n",
    "        missing_index = np.where(np.isnan(y))[0]\n",
    "\n",
    "        # other than missing value and its averate\n",
    "        y_delete = np.delete(y, missing_index)\n",
    "        y_mean = np.mean(y_delete)\n",
    "\n",
    "        # imputation\n",
    "        y[missing_index] = y_mean\n",
    "        return y\n",
    "\n",
    "class EuclideanImputation(MissingImputation):\n",
    "    def __init__(self, name='euclidean_imputation'):\n",
    "        super().__init__(name)\n",
    "\n",
    "class ManhattanImputation(MissingImputation):\n",
    "    def __init__(self, name='manhattan_imputation'):\n",
    "        super().__init__(name)\n",
    "\n",
    "class ChebyshevImputation(MissingImputation):\n",
    "    def __init__(self, name='chebyshev_imputation'):\n",
    "        super().__init__(name)\n",
    "\n",
    "class DefiniteRegressionImputation(MissingImputation):\n",
    "    def __init__(self, name='definite_regression_imputation'):\n",
    "        super().__init__(name)\n",
    "\n",
    "class ProbabilisticRegressionImputation(MissingImputation):\n",
    "    def __init__(self, name='probabilistic_regression_imputation'):\n",
    "        super().__init__(name)\n",
    "\n",
    "class StepwiseFeatureSelection(FeatureSelection):\n",
    "    def __init__(self, name='stepwise_feature_selection', parameters=None, candidates=None):\n",
    "        super().__init__(name, parameters, candidates)\n",
    "\n",
    "    def select_features(self, feature_matrix: np.ndarray, response_vector: np.ndarray, selected_features: np.ndarray, detected_outliers: np.ndarray) -> np.ndarray:\n",
    "        X, y = feature_matrix, response_vector\n",
    "        M, O = selected_features, detected_outliers.tolist()\n",
    "\n",
    "        X = np.delete(X,O,0)\n",
    "        X = X[:,M]\n",
    "        y = np.delete(y,O).reshape(-1,1)\n",
    "\n",
    "        # initialize\n",
    "        active_set = []\n",
    "        inactive_set = list(range(X.shape[1]))\n",
    "\n",
    "        # stepwise feature selection\n",
    "        for _ in range(self.parameters):\n",
    "            X_active = X[:,active_set]\n",
    "            r = y - X_active @ np.linalg.inv(X_active.T @ X_active) @ X_active.T @ y\n",
    "            correlation = X[:,inactive_set].T @ r\n",
    "\n",
    "            ind = np.argmax(np.abs(correlation))\n",
    "            active_set.append(inactive_set[ind])\n",
    "            inactive_set.remove(inactive_set[ind])\n",
    "        M = [M[i] for i in active_set]\n",
    "        return np.array(M)\n",
    "\n",
    "class MarginalScreening(FeatureSelection):\n",
    "    def __init__(self, name='marginal_screening', parameters=None, candidates=None):\n",
    "        super().__init__(name, parameters, candidates)\n",
    "\n",
    "    def select_features(self, feature_matrix: np.ndarray, response_vector: np.ndarray, selected_features: np.ndarray, detected_outliers: np.ndarray) -> np.ndarray:\n",
    "        X, y = feature_matrix, response_vector\n",
    "        M, O = selected_features, detected_outliers.tolist()\n",
    "\n",
    "        X = np.delete(X,O,0)\n",
    "        X = X[:,M]\n",
    "        y = np.delete(y,O).reshape(-1,1)\n",
    "\n",
    "        # marginal screening\n",
    "        XTy_abs = np.abs(X.T @ y).flatten()\n",
    "        sort_XTy_abs = np.argsort(XTy_abs)[::-1]\n",
    "\n",
    "        active_set = sort_XTy_abs[:self.parameters]\n",
    "        M = [M[i] for i in active_set]\n",
    "        return np.array(M)\n",
    "\n",
    "class Lasso(FeatureSelection):\n",
    "    def __init__(self, name='lasso', parameters=None, candidates=None):\n",
    "        super().__init__(name, parameters, candidates)\n",
    "\n",
    "    def select_features(self, feature_matrix: np.ndarray, response_vector: np.ndarray, selected_features: np.ndarray, detected_outliers: np.ndarray) -> np.ndarray:\n",
    "        X, y = feature_matrix, response_vector\n",
    "        M, O = selected_features, detected_outliers.tolist()\n",
    "\n",
    "        X = np.delete(X,O,0)\n",
    "        X = X[:,M]\n",
    "        y = np.delete(y,O).reshape(-1,1)\n",
    "\n",
    "        # lasso\n",
    "        lasso = lm.Lasso(alpha=self.parameters, fit_intercept=False, max_iter=5000, tol=1e-10)\n",
    "        lasso.fit(X, y)\n",
    "        active_set = np.where(lasso.coef_ != 0)[0]\n",
    "        M = [M[i] for i in active_set]\n",
    "        return np.array(M)\n",
    "\n",
    "class ElasticNet(FeatureSelection):\n",
    "    def __init__(self, name='elastic_net', parameters=None, candidates=None):\n",
    "        super().__init__(name, parameters, candidates)\n",
    "\n",
    "class Lars(FeatureSelection):\n",
    "    def __init__(self, name='lars', parameters=None, candidates=None):\n",
    "        super().__init__(name, parameters, candidates)\n",
    "\n",
    "class CookDistance(OutlierDetection):\n",
    "    def __init__(self, name='cook_distance', parameters=None, candidates=None):\n",
    "        super().__init__(name, parameters, candidates)\n",
    "\n",
    "    def detect_outliers(self, feature_matrix: np.ndarray, response_vector: np.ndarray, selected_features: np.ndarray, detected_outliers: np.ndarray) -> np.ndarray:\n",
    "        X, y = feature_matrix, response_vector\n",
    "        M, O = selected_features, detected_outliers.tolist()\n",
    "\n",
    "        X = np.delete(X, O, 0)\n",
    "        X = X[:, M]\n",
    "        y = np.delete(y, O).reshape(-1, 1)\n",
    "\n",
    "        num_data = list(range(X.shape[0]))\n",
    "        num_outlier_data = [i for i in num_data if i not in O]\n",
    "\n",
    "        # cook's distance\n",
    "        non_outlier = []\n",
    "        outlier = []\n",
    "        n, p = X.shape\n",
    "\n",
    "        hat_matrix = X @ np.linalg.inv(X.T @ X) @ X.T\n",
    "        Px = np.identity(n) - hat_matrix\n",
    "        threshold = self.parameters / n # threshold value\n",
    "\n",
    "        # outlier detection\n",
    "        for i in range(n):\n",
    "            ej = np.zeros((n, 1))\n",
    "            ej[i] = 1\n",
    "            hi = hat_matrix[i][i] # diagonal element of hat matrix\n",
    "            Di_1 = (y.T @ (Px @ ej @ ej.T @ Px) @ y) / (y.T @ Px @ y) # first term of Di\n",
    "            Di_2 = ((n - p) * hi) / (p * (1 - hi)**2) # second term of Di\n",
    "            Di = Di_1 * Di_2\n",
    "\n",
    "            if Di < threshold:\n",
    "                non_outlier.append(i)\n",
    "            else:\n",
    "                outlier.append(i)\n",
    "\n",
    "        O_ = [num_outlier_data[i] for i in outlier]\n",
    "        O = O + O_\n",
    "        return np.array(O)\n",
    "\n",
    "\n",
    "class Dffits(OutlierDetection):\n",
    "    def __init__(self, name='dffits', parameters=None, candidates=None):\n",
    "        super().__init__(name, parameters, candidates)\n",
    "\n",
    "class SoftIpod(OutlierDetection):\n",
    "    def __init__(self, name='soft_ipod', parameters=None, candidates=None):\n",
    "        super().__init__(name, parameters, candidates)\n",
    "\n",
    "\n",
    "\n",
    "def make_dataset():\n",
    "    feature_matrix = FeatureMatrix(PipelineStructure())\n",
    "    response_vector = ResponseVector(PipelineStructure())\n",
    "    return feature_matrix, response_vector\n",
    "\n",
    "def union(*inputs):\n",
    "    return Union()(*inputs)\n",
    "\n",
    "def intersection(*inputs):\n",
    "    return Intersection()(*inputs)\n",
    "\n",
    "def delete_outliers(feature_matrix, response_vector, detected_outliers):\n",
    "    return DeleteOutliers()(\n",
    "        feature_matrix,\n",
    "        response_vector,\n",
    "        detected_outliers\n",
    "        )\n",
    "\n",
    "def extract_features(feature_matrix, selected_features):\n",
    "    return ExtractFeatures()(feature_matrix, selected_features)\n",
    "\n",
    "def mean_value_imputation(feature_matrix, response_vector):\n",
    "    return MeanValueImputation()(feature_matrix, response_vector)\n",
    "\n",
    "def euclidean_imputation(feature_matrix, response_vector):\n",
    "    return EuclideanImputation()(feature_matrix, response_vector)\n",
    "\n",
    "def manhattan_imputation(feature_matrix, response_vector):\n",
    "    return ManhattanImputation()(feature_matrix, response_vector)\n",
    "\n",
    "def chebyshev_imputation(feature_matrix, response_vector):\n",
    "    return ChebyshevImputation()(feature_matrix, response_vector)\n",
    "\n",
    "def definite_regression_imputation(feature_matrix, response_vector):\n",
    "    return DefiniteRegressionImputation()(feature_matrix, response_vector)\n",
    "\n",
    "def probabilistic_regression_imputation(feature_matrix, response_vector):\n",
    "    return ProbabilisticRegressionImputation()(feature_matrix, response_vector)\n",
    "\n",
    "def stepwise_feature_selection(feature_matrix, response_vector, parameters=10, candidates=None):\n",
    "    return StepwiseFeatureSelection(parameters=parameters, candidates=candidates)(feature_matrix, response_vector)\n",
    "\n",
    "def marginal_screening(feature_matrix, response_vector, parameters=10, candidates=None):\n",
    "    return MarginalScreening(parameters=parameters, candidates=candidates)(feature_matrix, response_vector)\n",
    "\n",
    "def lasso(feature_matrix, response_vector, parameters=0.1, candidates=None):\n",
    "    return Lasso(parameters=parameters, candidates=candidates)(feature_matrix, response_vector)\n",
    "\n",
    "def elastic_net(feature_matrix, response_vector, parameters=None, candidates=None):\n",
    "    return ElasticNet(parameters=parameters, candidates=candidates)(feature_matrix, response_vector)\n",
    "\n",
    "def lars(feature_matrix, response_vector, parameters=None, candidates=None):\n",
    "    return Lars(parameters=parameters, candidates=candidates)(feature_matrix, response_vector)\n",
    "\n",
    "def cook_distance(feature_matrix, response_vector, parameters=3.0, candidates=None):\n",
    "    return CookDistance(parameters=parameters, candidates=candidates)(feature_matrix, response_vector)\n",
    "\n",
    "def dffits(feature_matrix, response_vector, parameters=None, candidates=None):\n",
    "    return Dffits(parameters=parameters, candidates=candidates)(feature_matrix, response_vector)\n",
    "\n",
    "def soft_ipod(feature_matrix, response_vector, parameters=None, candidates=None):\n",
    "    return SoftIpod(parameters=parameters, candidates=candidates)(feature_matrix, response_vector)\n",
    "\n",
    "def pipeline(feature_matrix, response_vector, selected_features):\n",
    "    pl_structure = selected_features.pl_structure\n",
    "    pl_structure.update('end', None)\n",
    "    pl_structure.make_graph()\n",
    "    return pl_structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_dataset()\n",
    "y_impute = mean_value_imputation(X, y)\n",
    "O = cook_distance(X, y_impute)\n",
    "X_del, y_del = delete_outliers(X, y_impute, O)\n",
    "M = marginal_screening(X_del, y_del)\n",
    "X_del_ext = extract_features(X_del, M)\n",
    "M_lasso = lasso(X_del_ext, y_del)\n",
    "M_sfs = stepwise_feature_selection(X_del_ext, y_del, parameters=5)\n",
    "M = union(M_lasso, M_sfs)\n",
    "pl = pipeline(X, y, M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  6 15 17]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "X = rng.normal(size=(100, 20))\n",
    "y = rng.normal(size=100)\n",
    "y[[3, 7, 84]] = np.nan\n",
    "M = pl(X, y)\n",
    "print(M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "mean_value_imputation_0\n",
      "cook_distance_0\n",
      "delete_0\n",
      "marginal_screening_0\n",
      "extract_0\n",
      "stepwise_feature_selection_0 lasso_0\n",
      "union_0\n",
      "end\n",
      "start None\n",
      "mean_value_imputation_0 <__main__.MeanValueImputation object at 0x7fe49e520b20>\n",
      "cook_distance_0 <__main__.CookDistance object at 0x7fe49e521630>\n",
      "delete_0 <__main__.DeleteOutliers object at 0x7fe4a81a3250>\n",
      "marginal_screening_0 <__main__.MarginalScreening object at 0x7fe4a8051f30>\n",
      "extract_0 <__main__.ExtractFeatures object at 0x7fe4a80508e0>\n",
      "lasso_0 <__main__.Lasso object at 0x7fe4a8053550>\n",
      "union_0 <__main__.Union object at 0x7fe4a80529b0>\n",
      "stepwise_feature_selection_0 <__main__.StepwiseFeatureSelection object at 0x7fe4a8053ac0>\n",
      "end None\n"
     ]
    }
   ],
   "source": [
    "from graphlib import TopologicalSorter\n",
    "\n",
    "graph = pl.graph\n",
    "\n",
    "ts = TopologicalSorter(graph)\n",
    "ts.prepare()\n",
    "while ts.is_active():\n",
    "    ready_nodes = ts.get_ready()\n",
    "    ts.done(*ready_nodes)\n",
    "    print(*ready_nodes)\n",
    "\n",
    "for key, value in pl.components.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "mean_value_imputation_3\n",
      "cook_distance_3 dffits_1 soft_ipod_1\n",
      "intersection_1\n",
      "union_3\n",
      "delete_3\n",
      "stepwise_feature_selection_3\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "X, y = make_dataset()\n",
    "y_impute = mean_value_imputation(X, y)\n",
    "O1 = cook_distance(X, y_impute)\n",
    "O2 = dffits(X, y_impute)\n",
    "O3 = soft_ipod(X, y_impute)\n",
    "O = union(intersection(O1, O2), O3)\n",
    "X_del, y_del = delete_outliers(X, y_impute, O)\n",
    "M = stepwise_feature_selection(X_del, y_del)\n",
    "pl = pipeline(X, y, M)\n",
    "\n",
    "ts = TopologicalSorter(pl.graph)\n",
    "ts.prepare()\n",
    "while ts.is_active():\n",
    "    ready_nodes = ts.get_ready()\n",
    "    ts.done(*ready_nodes)\n",
    "    print(*ready_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
