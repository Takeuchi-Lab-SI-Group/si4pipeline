{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## これは各アルゴリズムで区間の共通箇所を算出するパターン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sicore import polytope_to_interval, intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_nested_list(interval):\n",
    "    if isinstance(interval[0], list):  # 既に二重のリストである場合\n",
    "        return interval\n",
    "    else:  # 単一のリストである場合\n",
    "        return [interval]\n",
    "\n",
    "def interval_disassembly(interval1,interval2):\n",
    "    interval_list = []\n",
    "    i, j = 0, 0\n",
    "\n",
    "    while i < len(interval1) and j < len(interval2):\n",
    "        interval1 = convert_to_nested_list(interval1)\n",
    "        interval2 = convert_to_nested_list(interval2)\n",
    "        \n",
    "        L1, U1 = interval1[i]\n",
    "        L2, U2 = interval2[j]\n",
    "\n",
    "        # インターバルが重なっている場合\n",
    "        if U2 > L1 and U1 > L2:\n",
    "            new_L = max(L1,L2)\n",
    "            new_U = min(U1,U2)\n",
    "            interval_list.append([new_L,new_U])\n",
    "\n",
    "        # 次のインターバルに進みます\n",
    "        if U1 < U2:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    \n",
    "    return interval_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_si(a,b,z,X,A,O,Inter,k):\n",
    "\n",
    "    # yzの作成\n",
    "    yz_flatten = a + b * z\n",
    "    yz = yz_flatten.reshape(-1,1)\n",
    "\n",
    "    # 外れ値の除去(X,y,a,bに対して)\n",
    "    X = np.delete(X,[O],0)\n",
    "    yz = np.delete(yz,[O]).reshape(-1,1)\n",
    "\n",
    "    a = np.delete(a,[O])\n",
    "    b = np.delete(b,[O])\n",
    "\n",
    "    # 特徴の除去\n",
    "    X = X[:,A]\n",
    "\n",
    "    # Marginal Screening\n",
    "    XTyz_abs = np.abs(X.T @ yz).flatten()\n",
    "    sort_XTyz_abs = np.argsort(XTyz_abs)[::-1]\n",
    "\n",
    "    Az = sort_XTyz_abs[:k]\n",
    "    Acz = sort_XTyz_abs[k:]\n",
    "\n",
    "    # 切断区間算出\n",
    "    list_u = []\n",
    "    list_v = []\n",
    "\n",
    "    for i in Az:\n",
    "        xj = X[:,i]\n",
    "        sj = np.sign(np.dot(xj.T,yz))\n",
    "\n",
    "        e1 = sj * np.dot(xj.T,a)\n",
    "        e2 = sj * np.dot(xj.T,b)\n",
    "\n",
    "        for k in Acz:\n",
    "            xk = X[:,k]\n",
    "            \n",
    "            e3 = np.dot(xk.T,a)\n",
    "            e4 = np.dot(xk.T,b)\n",
    "\n",
    "            e5 = -np.dot(xk.T,a)\n",
    "            e6 = -np.dot(xk.T,b)\n",
    "\n",
    "            list_u.append(e4 - e2)\n",
    "            list_u.append(e6 - e2)\n",
    "\n",
    "            list_v.append(e1 - e3)\n",
    "            list_v.append(e1 - e5)\n",
    "    \n",
    "    nu_plus = np.Inf\n",
    "    nu_minus = np.NINF\n",
    "\n",
    "    for left,right in zip(list_u,list_v):\n",
    "        if np.around(left, 5) == 0:\n",
    "            if right <= 0:\n",
    "                raise Exception(\"エラー: 無効な条件です。\")\n",
    "            continue\n",
    "\n",
    "        temp = right / left\n",
    "\n",
    "        if left > 0: #論文の条件式より\n",
    "            nu_plus = min(temp,nu_plus) \n",
    "        else:\n",
    "            nu_minus = max(temp,nu_minus)\n",
    "    \n",
    "    assert nu_minus < nu_plus\n",
    "\n",
    "    inter_z = [nu_minus,nu_plus]\n",
    "    inter_z = interval_disassembly(inter_z,Inter)\n",
    "\n",
    "    # 元の特徴に基づいた選択結果\n",
    "    Az = [A[i] for i in Az]\n",
    "\n",
    "    return Az,inter_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_si(a,b,z,X,A,O,Inter,lamda):\n",
    "\n",
    "    # yzの作成\n",
    "    yz_flatten = a + b * z\n",
    "    yz = yz_flatten.reshape(-1,1)\n",
    "\n",
    "    # 外れ値の除去(X,y,a,bに対して)\n",
    "    X = np.delete(X,[O],0)\n",
    "    yz = np.delete(yz,[O]).reshape(-1,1)\n",
    "\n",
    "    a = np.delete(a,[O])\n",
    "    b = np.delete(b,[O])\n",
    "\n",
    "    # 特徴の除去\n",
    "    X = X[:,A]\n",
    "\n",
    "    # lasso\n",
    "    clf = Lasso(alpha=lamda,fit_intercept=False,max_iter=5000,tol=1e-10)\n",
    "    clf.fit(X,yz)\n",
    "    coef = clf.coef_\n",
    "\n",
    "    # lassoによる結果(インデックス表示)\n",
    "    Az = np.where(coef != 0)[0].tolist() #coefが0でないものをリストとして表示\n",
    "    Acz = [i for i in X.shape[1] if i not in Az]\n",
    "    s = np.sign(coef[Az])\n",
    "\n",
    "    # XA,XAcの算出\n",
    "    XA = X[:,Az]\n",
    "    XAc = X[:,Acz]\n",
    "\n",
    "    # 切断区間\n",
    "    lasso_condition = []\n",
    "    Pm = XA @ np.linalg.inv(XA.T @ XA) @ XA.T\n",
    "    XA_plus = np.linalg.inv(XA.T @ XA) @ XA.T\n",
    "\n",
    "    A0_plus = 1 / (lamda*X.shape[0]) * (XAc.T @ (np.identity(X.shape[0]) - Pm) ) \n",
    "    A0_minus = 1 / (lamda*X.shape[0]) * (-1 * XAc.T @ (np.identity(X.shape[0]) - Pm))\n",
    "    b0_plus = np.ones(XAc.shape[1]) - XAc.T @ XA_plus.T @ s\n",
    "    b0_minus = np.ones(XAc.shape[1]) + XAc.T @ XA_plus.T @ s\n",
    "\n",
    "    A1 = -1 * np.diag(s) @ np.linalg.inv(XA.T @ XA) @ XA.T\n",
    "    b1 = -1 * (lamda*X.shape[0]) * np.diag(s) @ np.linalg.inv(XA.T @ XA) @ s\n",
    "\n",
    "    lasso_condition = [[A0_plus,b0_plus],[A0_minus,b0_minus],[A1,b1]]\n",
    "\n",
    "    list_u = []\n",
    "    list_v = []\n",
    "\n",
    "    nu_plus = np.Inf\n",
    "    nu_minus = np.NINF\n",
    "\n",
    "    for Aj,bj in lasso_condition:\n",
    "        uj = np.dot(Aj,b).reshape(-1).tolist()\n",
    "        vj = (bj - np.dot(Aj, a)).reshape(-1).tolist()\n",
    "        list_u.extend(uj)\n",
    "        list_v.extend(vj)\n",
    "    \n",
    "    for left,right in zip(list_u,list_v):\n",
    "\n",
    "        if np.round(left,5) == 0:\n",
    "            if right <= 0:\n",
    "                raise Exception(\"エラー: 無効な条件です。\")\n",
    "            continue\n",
    "\n",
    "        temp = right / left\n",
    "\n",
    "        if left > 0:\n",
    "            nu_plus = min(temp,nu_plus)\n",
    "        else:\n",
    "            nu_minus = max(temp,nu_minus)\n",
    "    \n",
    "    assert nu_minus < nu_plus\n",
    "\n",
    "    inter_z = [nu_minus,nu_plus]\n",
    "    inter_z = interval_disassembly(inter_z,Inter)\n",
    "\n",
    "    # 元の特徴に基づいた結果\n",
    "    Az = [A[i] for i in Az]\n",
    "\n",
    "    return Az,inter_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFS SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfs_si(a,b,z,X,A,O,Inter,k):\n",
    "    \n",
    "    # yzの作成\n",
    "    yz_flatten = a + b * z\n",
    "    yz = yz_flatten.reshape(-1,1)\n",
    "\n",
    "    # 外れ値の除去(X,y,a,bに対して)\n",
    "    X = np.delete(X,[O],0)\n",
    "    yz = np.delete(yz,[O]).reshape(-1,1)\n",
    "\n",
    "    a = np.delete(a,[O])\n",
    "    b = np.delete(b,[O])\n",
    "\n",
    "    # 特徴の除去\n",
    "    X = X[:,A]\n",
    "\n",
    "    # sfs\n",
    "    Az = []\n",
    "    Acz = list(range(X.shape[1]))\n",
    "    s = []\n",
    "\n",
    "    for i in range(k):\n",
    "        XA = X[:,Az]\n",
    "        r = yz - XA @ np.linalg.pinv(XA.T @ XA) @ XA.T @ yz\n",
    "        correlation = X[:,Acz].T @ r \n",
    "\n",
    "        index = np.argmax(np.abs(correlation)) #何番目の要素が最大か？\n",
    "\n",
    "        s.append(np.sign(correlation[index]))\n",
    "\n",
    "        Az.append(Acz[index])\n",
    "        Acz.remove(Acz[index])\n",
    "\n",
    "    # 切断区間\n",
    "    list_u = []\n",
    "    list_v = []\n",
    "    Acz = list(range(X.shape[1])) # 選択されなかった特徴，最初は全特徴を含む\n",
    "\n",
    "    for i in range(k):\n",
    "        XA = X[:,Az[0:i]] # 残差r_t 計算用\n",
    "        x_jt = X[:,Az[i]] # 選択イベント x_\\hat{j}_{t} \n",
    "        s_t = s[i] # \\hat{s}_{t} \n",
    "        F = np.identity(X.shape[0]) - XA @ np.linalg.pinv(XA.T @ XA) @ XA.T\n",
    "        Acz.remove(Az[i])\n",
    "\n",
    "        for j in Acz:\n",
    "            x_j = X[:,j]\n",
    "\n",
    "            u1 = np.dot((x_j - s_t * x_jt).T,np.dot(F,b))\n",
    "            v1 = np.dot(-(x_j - s_t * x_jt).T,np.dot(F,a))\n",
    "            u2 = np.dot((- x_j - s_t * x_jt).T,np.dot(F,b))\n",
    "            v2 = np.dot( -(- x_j - s_t * x_jt).T,np.dot(F,a))\n",
    "\n",
    "            list_u.append(u1)\n",
    "            list_u.append(u2)\n",
    "            list_v.append(v1)\n",
    "            list_v.append(v2)\n",
    "    \n",
    "    nu_plus = np.Inf\n",
    "    nu_minus = np.NINF\n",
    "\n",
    "    for m in range(len(list_u)):\n",
    "        left = list_u[m]\n",
    "        right = list_v[m]\n",
    "\n",
    "        if np.around(left, 5) == 0:\n",
    "            if right <= 0:\n",
    "                print(\"ERROR\")\n",
    "                \n",
    "            continue\n",
    "\n",
    "        temp = right / left\n",
    "\n",
    "        if left > 0: #論文の条件式より\n",
    "            nu_plus = min(temp,nu_plus) \n",
    "        else:\n",
    "            nu_minus = max(temp,nu_minus)\n",
    "    \n",
    "    assert nu_minus < nu_plus\n",
    "\n",
    "    inter_z = [nu_minus,nu_plus]\n",
    "    inter_z = interval_disassembly(inter_z,Inter)\n",
    "\n",
    "    # 元の特徴に基づいた結果\n",
    "    Az = [A[i] for i in Az]\n",
    "\n",
    "    return Az,inter_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# sfs\n",
    "X = np.random.randn(100,10)\n",
    "y = np.random.randn(100)\n",
    "\n",
    "a = [0,2,5,7,9]\n",
    "k = 3\n",
    "X = X[:,a]\n",
    "\n",
    "A = []\n",
    "s = []\n",
    "Ac = list(range(X.shape[1]))\n",
    "\n",
    "for i in range(k):\n",
    "    XA = X[:,A]\n",
    "    r = y - XA @ np.linalg.pinv(XA.T @ XA) @ XA.T @ y\n",
    "    correlation = X[:,Ac].T @ r \n",
    "\n",
    "    index = np.argmax(np.abs(correlation)) #何番目の要素が最大か？\n",
    "\n",
    "    s.append(np.sign(correlation[index]))\n",
    "\n",
    "    A.append(Ac[index])\n",
    "    Ac.remove(Ac[index])\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cook SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cook_si(a,b,z,X,A,O,Inter,lamda):\n",
    "\n",
    "    # yzの作成\n",
    "    yz_flatten = a + b * z\n",
    "    yz = yz_flatten.reshape(-1,1)\n",
    "\n",
    "    # 最後に最終的に得られる外れ値集合を求めるのに使用する\n",
    "    num_data = list(range(X.shape[0]))\n",
    "    num_outlier_data = [x for x in num_data if x not in O]\n",
    "\n",
    "    # 外れ値の除去(X,y,a,bに対して)\n",
    "    X = np.delete(X,[O],0)\n",
    "    yz = np.delete(yz,[O]).reshape(-1,1)\n",
    "\n",
    "    a = np.delete(a,[O])\n",
    "    b = np.delete(b,[O])\n",
    "\n",
    "    # 特徴の除去\n",
    "    X = X[:,A]\n",
    "\n",
    "    # cook's distance\n",
    "    non_outlier = []\n",
    "    outlier = []\n",
    "    n,p = X.shape\n",
    "\n",
    "    hat_matrix =  X @ np.linalg.inv(X.T @ X) @ X.T\n",
    "    Px = np.identity(n) - hat_matrix\n",
    "    threads = lamda / n #しきい値の設定\n",
    "\n",
    "    # 外れ値の除去\n",
    "    for i in range(n):\n",
    "        ej = np.zeros((n,1))\n",
    "        ej[i] = 1\n",
    "        hi = hat_matrix[i][i] #Pxの対角成分\n",
    "        Di_1 = (y.T @ (Px @ ej @ ej.T @ Px) @ y) / (y.T @ Px @ y) # Diの1項目\n",
    "        Di_2 = ((n - p) * hi) / (p * (1 - hi)**2) # Diの2項目\n",
    "        Di = Di_1 * Di_2\n",
    "\n",
    "        if Di < threads:\n",
    "            non_outlier.append(i)\n",
    "        else:\n",
    "            outlier.append(i)\n",
    "    \n",
    "    # 切断区間\n",
    "    inter_z = [-np.inf, np.inf]\n",
    "    B = np.zeros(n)\n",
    "    C = 0 \n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        ej = np.zeros((n,1))\n",
    "        ej[i] = 1\n",
    "        hi = hat_matrix[i][i]\n",
    "        H_1 = ((n - p) * hi) * Px @ ej @ ej.T @ Px\n",
    "        H_2 = ((lamda * p * (1 - hi)**2) / n ) * Px\n",
    "        H = H_1 - H_2\n",
    "\n",
    "        if i in outlier:\n",
    "            H = -H\n",
    "\n",
    "        intervals = polytope_to_interval(a,b,H,B,C)\n",
    "        inter_z = intersection(intervals,inter_z)\n",
    "    \n",
    "    inter_z = interval_disassembly(inter_z,Inter)\n",
    "    \n",
    "    # 元の特徴に基づいた結果\n",
    "    outlier2 = [num_outlier_data[i] for i in outlier]\n",
    "    Oz = O + outlier2\n",
    "    \n",
    "    return Oz,inter_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2連続で外れ値除去する時"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]\n",
      " [21 22 23 24]\n",
      " [29 30 31 32]\n",
      " [37 38 39 40]] [[ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 6]\n",
      " [ 8]\n",
      " [10]]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(y,[outlier])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(X,y)\n\u001b[0;32m---> 11\u001b[0m non_outlier,outlier \u001b[38;5;241m=\u001b[39m \u001b[43moutlier_removel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcook_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(outlier)\n",
      "File \u001b[0;32m~/Desktop/SI B4/missing_outlier_FS_check_code/outlier_removel.py:16\u001b[0m, in \u001b[0;36mcook_distance\u001b[0;34m(X, y, lamda)\u001b[0m\n\u001b[1;32m     14\u001b[0m n,p \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 閾値の計算\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m hat_matrix \u001b[38;5;241m=\u001b[39m  X \u001b[38;5;241m@\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     17\u001b[0m Px \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39midentity(n) \u001b[38;5;241m-\u001b[39m hat_matrix\n\u001b[1;32m     18\u001b[0m threads \u001b[38;5;241m=\u001b[39m lamda \u001b[38;5;241m/\u001b[39m n \u001b[38;5;66;03m#しきい値の設定\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python310/lib/python3.10/site-packages/numpy/linalg/linalg.py:545\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    543\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    544\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 545\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python310/lib/python3.10/site-packages/numpy/linalg/linalg.py:88\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "import outlier_removel\n",
    "X = list(range(1,41))\n",
    "y = list(range(1,11))\n",
    "outlier = [0,4,6,8]\n",
    "y = np.array(y).reshape(10,)\n",
    "X = np.array(X).reshape(10,4)\n",
    "X = np.delete(X,[outlier],0)\n",
    "y = np.delete(y,[outlier]).reshape(-1,1)\n",
    "\n",
    "print(X,y)\n",
    "non_outlier,outlier = outlier_removel.cook_distance(X,y,0.3)\n",
    "print(outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[-0.89546656  0.3869025  -0.51080514 -1.18063218 -0.02818223  0.42833187\n",
      "  0.06651722  0.3024719  -0.63432209 -0.36274117]\n",
      "[3, 4, 5, 6, 7, 8, 9]\n",
      "[-1.18063218 -0.02818223  0.42833187  0.06651722  0.3024719  -0.63432209\n",
      " -0.36274117]\n",
      "[0, 3, 4, 5]\n",
      "[3, 4, 5, 6, 7, 8, 9]\n",
      "[3, 6, 7, 8]\n",
      "[3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "import outlier_removel\n",
    "np.random.seed(0)\n",
    "data_list = list(range(10))\n",
    "print(data_list)\n",
    "X = np.random.randn(10,5)\n",
    "y = np.random.randn(10,)\n",
    "print(y)\n",
    "outlier = [0,1,2]\n",
    "data_outlier = [x for x in data_list if x not in outlier]\n",
    "print(data_outlier)\n",
    "X = np.delete(X,[outlier],0)\n",
    "y = np.delete(y,[outlier]).reshape(-1,)\n",
    "print(y)\n",
    "non_outlier,outlier = outlier_removel.cook_distance(X,y,3)\n",
    "print(outlier)\n",
    "outlier_shin = [x for x in data_outlier if x in outlier]\n",
    "print(data_outlier)\n",
    "outlier_sin = [data_outlier[i] for i in outlier]\n",
    "print(outlier_sin)\n",
    "print(outlier_shin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[-0.89546656  0.3869025  -0.51080514 -1.18063218 -0.02818223  0.42833187\n",
      "  0.06651722  0.3024719  -0.63432209 -0.36274117]\n",
      "[3, 4, 5, 6, 7, 8, 9]\n",
      "[-1.18063218 -0.02818223  0.42833187  0.06651722  0.3024719  -0.63432209\n",
      " -0.36274117]\n",
      "[0, 3, 4, 5]\n",
      "[3, 6, 7, 8]\n",
      "[0, 1, 2, 3, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "import outlier_removel\n",
    "np.random.seed(0)\n",
    "data_list = list(range(10))\n",
    "print(data_list)\n",
    "X = np.random.randn(10,5)\n",
    "y = np.random.randn(10,)\n",
    "print(y)\n",
    "O = [0,1,2]\n",
    "# データから外れ値を除いたインデックスを取得\n",
    "data_outlier = [x for x in data_list if x not in O]\n",
    "print(data_outlier)\n",
    "X = np.delete(X,[O],0)\n",
    "y = np.delete(y,[O]).reshape(-1,)\n",
    "print(y)\n",
    "non_outlier,outlier = outlier_removel.cook_distance(X,y,3)\n",
    "print(outlier)\n",
    "# data_outlierから外れ値に該当するインデックスを取得\n",
    "outlier_sin = [data_outlier[i] for i in outlier]\n",
    "# 最終的な外れ値集合を取得\n",
    "O = O + outlier_sin\n",
    "print(outlier_sin)\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最終盤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 6, 7, 8]\n",
      "[0, 1, 2, 3, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "import outlier_removel\n",
    "np.random.seed(0)\n",
    "data_list = list(range(10))\n",
    "X = np.random.randn(10,5)\n",
    "y = np.random.randn(10,)\n",
    "# 最初の外れ値集合\n",
    "O = [0,1,2]\n",
    "# データから外れ値を除いたインデックスを取得\n",
    "data_outlier = [x for x in data_list if x not in O]\n",
    "\n",
    "# X,yから外れ値に該当するデータを削除\n",
    "X = np.delete(X,[O],0)\n",
    "y = np.delete(y,[O]).reshape(-1,)\n",
    "\n",
    "# クックの距離による外れ値除去\n",
    "non_outlier,outlier = outlier_removel.cook_distance(X,y,3)\n",
    "\n",
    "# data_outlierから外れ値に該当するインデックスを取得\n",
    "outlier_sin = [data_outlier[i] for i in outlier]\n",
    "# 最終的な外れ値集合を取得\n",
    "O = O + outlier_sin\n",
    "\n",
    "print(outlier_sin)\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DFFITS SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dffits_si(a,b,z,X,A,O,Inter,lamda):\n",
    "\n",
    "    # yzの作成\n",
    "    yz_flatten = a + b * z\n",
    "    yz = yz_flatten.reshape(-1,1)\n",
    "\n",
    "    # 最後に最終的に得られる外れ値集合を求めるのに使用する\n",
    "    num_data = list(range(X.shape[0]))\n",
    "    num_outlier_data = [x for x in num_data if x not in O]\n",
    "\n",
    "    # 外れ値の除去(X,y,a,bに対して)\n",
    "    X = np.delete(X,[O],0)\n",
    "    yz = np.delete(yz,[O]).reshape(-1,1)\n",
    "\n",
    "    a = np.delete(a,[O])\n",
    "    b = np.delete(b,[O])\n",
    "\n",
    "    # 特徴の除去\n",
    "    X = X[:,A]\n",
    "\n",
    "    # DFFITS\n",
    "    non_outlier = []\n",
    "    outlier = []\n",
    "    n,p = X.shape\n",
    "\n",
    "    hat_matrix =  X @ np.linalg.inv(X.T @ X) @ X.T\n",
    "    Px = np.identity(n) - hat_matrix\n",
    "    threads = (lamda * p) / (n - p) #しきい値の設定\n",
    "\n",
    "    # 外れ値の除去\n",
    "    for i in range(n):\n",
    "        ej = np.zeros((n,1))\n",
    "        ej[i] = 1\n",
    "        hi = hat_matrix[i][i] #Pxの対角成分\n",
    "        DFFITSi_1 = np.sqrt(hi * (n - p - 1)) / (1 - hi) # DFFITSの片側\n",
    "        DFFITSi_2_denominator = y.T @ Px @ y - ((y.T @ Px @ ej @ ej.T @ Px @ y) / (1 - hi))\n",
    "        DFFITSi_2 = (ej.T @ Px @ y) / np.sqrt(DFFITSi_2_denominator )\n",
    "        DFFITSi = DFFITSi_1 * DFFITSi_2\n",
    "\n",
    "        if DFFITSi**2 < threads:\n",
    "            non_outlier.append(i)\n",
    "        else:\n",
    "            outlier.append(i)\n",
    "    \n",
    "    # 切断区間\n",
    "    inter_z = [-np.inf, np.inf]\n",
    "    B = np.zeros(n)\n",
    "    C = 0 \n",
    "\n",
    "    for i in range(n):\n",
    "        ej = np.zeros((n,1))\n",
    "        ej[i] = 1\n",
    "        hi = hat_matrix[i][i]\n",
    "        H_1_1 = ((hi * (n - p - 1)) / (1 - hi)**2) + ((lamda * p) / ((n - p)*(1 - hi)))\n",
    "        H_1 = H_1_1 * Px @ ej @ ej.T @ Px \n",
    "        H_2 = ((lamda * p)/(n - p)) * Px\n",
    "    \n",
    "        H = H_1 - H_2\n",
    "        if i in outlier:\n",
    "            H = - H\n",
    "\n",
    "        intervals = polytope_to_interval(a,b,H,B,C)\n",
    "        inter_z = intersection(intervals,inter_z)\n",
    "    \n",
    "    inter_z = interval_disassembly(inter_z,Inter)\n",
    "\n",
    "    # 元の特徴に基づいた結果\n",
    "    outlier2 = [num_outlier_data[i] for i in outlier]\n",
    "    Oz = O + outlier2\n",
    "    \n",
    "    return Oz,inter_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# soft-IPOD SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft-IPODのハイパーパラメータは外部から入力する感じ\n",
    "def soft_ipod_si(a,b,z,X,A,O,Inter,lamda):\n",
    "    \n",
    "    # yzの作成\n",
    "    yz_flatten = a + b * z\n",
    "    yz = yz_flatten.reshape(-1,1)\n",
    "\n",
    "    # 最後に最終的に得られる外れ値集合を求めるのに使用する\n",
    "    num_data = list(range(X.shape[0]))\n",
    "    num_outlier_data = [x for x in num_data if x not in O]\n",
    "\n",
    "    # 外れ値の除去(X,y,a,bに対して)\n",
    "    X = np.delete(X,[O],0)\n",
    "    yz = np.delete(yz,[O]).reshape(-1,1)\n",
    "\n",
    "    a = np.delete(a,[O])\n",
    "    b = np.delete(b,[O])\n",
    "\n",
    "    # 特徴の除去\n",
    "    X = X[:,A]\n",
    "\n",
    "    # soft-IPODの準備\n",
    "    n,p = X.shape\n",
    "\n",
    "    hat_matrix =  X @ np.linalg.inv(X.T @ X) @ X.T\n",
    "    PXperp = np.identity(n) - hat_matrix\n",
    "    PXperpy = PXperp @ y\n",
    "\n",
    "    # soft-IPODの実行\n",
    "    clf = Lasso(alpha=lamda,fit_intercept=False,max_iter=5000,tol=1e-10)\n",
    "    clf.fit(PXperp,PXperpy)\n",
    "    coef = clf.coef_\n",
    "    outlier = np.where(coef!=0)[0].tolist() #外れ値\n",
    "    non_outlier = np.where(coef==0)[0].tolist() #非外れ値\n",
    "    s = np.sign(coef[outlier])\n",
    "\n",
    "    # 切断区間\n",
    "    soft_IPOD_condition = []\n",
    "    # PXperpを計算\n",
    "    I = np.identity(n)\n",
    "    X_caron =  I - X @ np.linalg.inv(X.T @ X) @ X.T\n",
    "\n",
    "    X_caron_M = X_caron[:,non_outlier]\n",
    "    X_caron_Mc = X_caron[:,outlier]\n",
    "\n",
    "    PX_caron_Mc_perp = I - X_caron_Mc @ np.linalg.inv(X_caron_Mc.T @ X_caron_Mc) @ X_caron_Mc.T\n",
    "    X_caron_Mc_plus = X_caron_Mc @ np.linalg.inv(X_caron_Mc.T @ X_caron_Mc)\n",
    "\n",
    "    # 以下はy_caronに対する係数\n",
    "    A0_plus = (1 / (lamda * n)) * (X_caron_M.T @ PX_caron_Mc_perp @ X_caron)\n",
    "    A0_minus = -1 *  (1 / (lamda * n)) * (X_caron_M.T @ PX_caron_Mc_perp @ X_caron)\n",
    "\n",
    "    b0_plus = np.ones(len(non_outlier)) - X_caron_M.T @ X_caron_Mc_plus @ s\n",
    "    b0_minus = np.ones(len(non_outlier)) + X_caron_M.T @ X_caron_Mc_plus @ s\n",
    "\n",
    "    A1 = -1 * np.diag(s) @ np.linalg.inv(X_caron_Mc.T @ X_caron_Mc) @ X_caron_Mc.T @ X_caron\n",
    "    b1 = -1 * n * lamda * np.diag(s) @ np.linalg.inv(X_caron_Mc.T @ X_caron_Mc) @ s\n",
    "\n",
    "    soft_IPOD_condition = [[A0_plus,b0_plus],[A0_minus,b0_minus],[A1,b1]]\n",
    "\n",
    "    list_u = []\n",
    "    list_v = []\n",
    "\n",
    "    nu_plus = np.Inf\n",
    "    nu_minus = np.NINF\n",
    "\n",
    "    for j in soft_IPOD_condition:\n",
    "        Aj,bj = j\n",
    "        uj = ((Aj @ b).reshape(-1)).tolist()\n",
    "        vj = ((bj - Aj @ a).reshape(-1)).tolist()\n",
    "        list_u.extend(uj)\n",
    "        list_v.extend(vj)\n",
    "\n",
    "    for m in range(len(list_u)):\n",
    "        left = list_u[m]\n",
    "        right = list_v[m]\n",
    "\n",
    "        if np.around(left,5) == 0:\n",
    "            if right <= 0:\n",
    "                print(\"ERROR\")\n",
    "                \n",
    "            continue\n",
    "\n",
    "        temp = right / left\n",
    "\n",
    "        if left > 0:\n",
    "            nu_plus = min(temp,nu_plus)\n",
    "        else:\n",
    "            nu_minus = max(temp,nu_minus)\n",
    "\n",
    "    assert nu_minus < nu_plus\n",
    "\n",
    "    inter_z = [nu_minus,nu_plus]\n",
    "    inter_z = interval_disassembly(inter_z,Inter)\n",
    "\n",
    "    # 元の特徴に基づいた結果\n",
    "    outlier2 = [num_outlier_data[i] for i in outlier]\n",
    "    Oz = O + outlier2\n",
    "\n",
    "    return Oz,inter_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 欠損値補完"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平均値補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_value_imputation(X,y,sigma):\n",
    "\n",
    "    # データ数の取得\n",
    "    n = y.shape[0]\n",
    "\n",
    "    # 欠損箇所を取得\n",
    "    missing_index = np.where(np.isnan(y))[0]\n",
    "\n",
    "    # index_random番目の以外のyを取得\n",
    "    y_delete = np.delete(y, missing_index)\n",
    "\n",
    "    # 平均値を計算\n",
    "    y_mean = np.mean(y_delete)\n",
    "\n",
    "    # 欠損値補完，(100,1)に変換\n",
    "    y[missing_index] = y_mean\n",
    "    y = y.reshape((n,1))\n",
    "\n",
    "    # yの分散共分散行列の変更\n",
    "    cov = np.identity(n)\n",
    "\n",
    "    # 該当する箇所の分散共分散を変更していく\n",
    "    # (1 / (n - 1)) * (y_1 + y_2 + ... + y_n-1)\n",
    "    each_var_cov_value = sigma**2 / (n - len(missing_index))\n",
    "\n",
    "    cov[:,missing_index] = each_var_cov_value\n",
    "    cov[missing_index,:] = each_var_cov_value\n",
    "\n",
    "    return X,y,cov "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hot-deck法  (ユークリッド，マンハッタン，チェビシェフ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユークリッド距離\n",
    "def euclidean_imputation(X,y,sigma):\n",
    "\n",
    "    # 欠損箇所を取得\n",
    "    missing_index = np.where(np.isnan(y))[0]\n",
    "\n",
    "    idx_list = []\n",
    "\n",
    "    for index_random in missing_index:\n",
    "        # ユークリッド距離の計算，二種類\n",
    "        X_euclidean = np.sqrt(np.sum((X - X[index_random])**2, axis=1))\n",
    "\n",
    "        # 欠損箇所を除いて，ユークリッド距離が最小になる\n",
    "        X_euclidean_deleted = np.delete(X_euclidean, missing_index)\n",
    "        idx_deleted = np.argmin(X_euclidean_deleted) # missing_indexを除いたindex\n",
    "\n",
    "        # idx_deletedは欠損値を除いたデータセットに対するものなので、元のデータセットに対する正しいインデックスを得るためには、欠損値のインデックスが現在のインデックスより小さい場合には+1します。\n",
    "        # idx_deletedを求めた時と同じ条件(欠損箇所を除いた)で，idxを求める\n",
    "        original_indices = np.arange(len(X_euclidean))  # 元のデータセットのインデックス\n",
    "        valid_indices = np.delete(original_indices, missing_index)  # 欠損値を除いたインデックス\n",
    "        idx = valid_indices[idx_deleted]  # 欠損値を除いたインデックスから元のインデックスを取得\n",
    "\n",
    "        y[index_random] = y[idx]\n",
    "\n",
    "        idx_list.append(idx)\n",
    "\n",
    "    y = y.reshape((X.shape[0],1))\n",
    "\n",
    "    # 6. 分散共分散行列の作成\n",
    "    cov = np.identity(X.shape[0])\n",
    "\n",
    "    for index_random,idx in zip(missing_index,idx_list):\n",
    "        cov[index_random,idx] = sigma**2\n",
    "        cov[idx,index_random] = sigma**2\n",
    "\n",
    "    return X,y,cov\n",
    "\n",
    "# マンハッタン距離\n",
    "def manhattan_imputation(X,y,sigma):\n",
    "\n",
    "    # 欠損箇所を取得\n",
    "    missing_index = np.where(np.isnan(y))[0]\n",
    "\n",
    "    idx_list = []\n",
    "\n",
    "    for index_random in missing_index:\n",
    "\n",
    "        # マンハッタン距離の計算\n",
    "        X_manhattan = np.sum(np.abs(X - X[index_random]), axis=1)\n",
    "\n",
    "        # 欠損箇所を除いて，マンハッタン距離が最小になる\n",
    "        X_manhattan_deleted = np.delete(X_manhattan, missing_index)\n",
    "        idx_deleted = np.argmin(X_manhattan_deleted) # missing_indexを除いたindex\n",
    "\n",
    "        # idx_deletedは欠損値を除いたデータセットに対するものなので、元のデータセットに対する正しいインデックスを得るためには、欠損値のインデックスが現在のインデックスより小さい場合には+1します。\n",
    "        # idx_deletedを求めた時と同じ条件(欠損箇所を除いた)で，idxを求める\n",
    "        original_indices = np.arange(len(X_manhattan))  # 元のデータセットのインデックス\n",
    "        valid_indices = np.delete(original_indices, missing_index)  # 欠損値を除いたインデックス\n",
    "        idx = valid_indices[idx_deleted]  # 欠損値を除いたインデックスから元のインデックスを取得\n",
    "\n",
    "        y[index_random] = y[idx]\n",
    "\n",
    "        idx_list.append(idx)\n",
    "\n",
    "    y = y.reshape((X.shape[0],1))\n",
    "\n",
    "    # 6. 分散共分散行列の作成\n",
    "    cov = np.identity(X.shape[0])\n",
    "\n",
    "    for index_random,idx in zip(missing_index,idx_list):\n",
    "        cov[index_random,idx] = sigma**2\n",
    "        cov[idx,index_random] = sigma**2\n",
    "\n",
    "    return X,y,cov\n",
    "\n",
    "# チェビシェフの距離\n",
    "def chebyshev_imputation(X,y,sigma):\n",
    "\n",
    "    # 欠損箇所を取得\n",
    "    missing_index = np.where(np.isnan(y))[0]\n",
    "\n",
    "    idx_list = []\n",
    "\n",
    "    for index_random in missing_index:\n",
    "        # チェビシェフの距離を求める\n",
    "        X_chebyshev = np.max(np.abs(X - X[index_random]), axis=1)\n",
    "\n",
    "        # 欠損箇所を除いて，チェビシェフの距離が最小になる\n",
    "        X_chebyshev_deleted = np.delete(X_chebyshev, missing_index)\n",
    "        idx_deleted = np.argmin(X_chebyshev_deleted) # missing_indexを除いたindex\n",
    "\n",
    "        # idx_deletedは欠損値を除いたデータセットに対するものなので、元のデータセットに対する正しいインデックスを得るためには、欠損値のインデックスが現在のインデックスより小さい場合には+1します。\n",
    "        # idx_deletedを求めた時と同じ条件(欠損箇所を除いた)で，idxを求める\n",
    "        original_indices = np.arange(len(X_chebyshev))  # 元のデータセットのインデックス\n",
    "        valid_indices = np.delete(original_indices, missing_index)  # 欠損値を除いたインデックス\n",
    "        idx = valid_indices[idx_deleted]  # 欠損値を除いたインデックスから元のインデックスを取得\n",
    "\n",
    "        y[index_random] = y[idx]\n",
    "\n",
    "        idx_list.append(idx)\n",
    "\n",
    "    y = y.reshape((X.shape[0],1))\n",
    "\n",
    "    # 6. 分散共分散行列の作成\n",
    "    cov = np.identity(X.shape[0])\n",
    "\n",
    "    for index_random,idx in zip(missing_index,idx_list):\n",
    "            cov[index_random,idx] = sigma**2\n",
    "            cov[idx,index_random] = sigma**2\n",
    "\n",
    "    return X,y,cov\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回帰代入法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確定的\n",
    "def regression_definite_imputation(X,y,sigma):\n",
    "    # 欠損箇所を取得\n",
    "    n = y.shape[0]\n",
    "    missing_index = np.where(np.isnan(y))[0]\n",
    "\n",
    "    # missing_index番目の以外のX,yを取得\n",
    "    X_delete = np.delete(X, missing_index, 0)\n",
    "    y_delete = np.delete(y, missing_index, 0).reshape(-1,1)\n",
    "\n",
    "    cov = np.identity(n)\n",
    "\n",
    "    # 回帰係数の推定\n",
    "    beta_hat = np.linalg.inv(X_delete.T @ X_delete) @ X_delete.T @ y_delete\n",
    "\n",
    "    data_list = list(range(n))\n",
    "\n",
    "    # 各欠損箇所に対して\n",
    "    for index_random in missing_index:\n",
    "\n",
    "        # 欠損しているデータを取得\n",
    "        X_missing = X[index_random]\n",
    "\n",
    "        # beta_hatにより欠損していた値を補完\n",
    "        y_new = X_missing @ beta_hat\n",
    "\n",
    "        # 欠損箇所の補完\n",
    "        y[index_random] = y_new\n",
    "\n",
    "        # 分散の計算\n",
    "        # 列ごとに分散，共分散を計算しているイメージ\n",
    "        for i in data_list:\n",
    "            # データの抽出\n",
    "            each_x = X[i]\n",
    "    \n",
    "            # 分散の計算\n",
    "            var_missing = sigma**2 * each_x @ np.linalg.inv(X_delete.T @ X_delete) @ X_missing.T\n",
    "            #var_missing = (sigma * each_x.T @ np.linalg.inv(X_delete.T @ X_delete) @ X_missing)[0,0]\n",
    "\n",
    "            # 分散共分散行列に追加\n",
    "            cov[i,index_random] = var_missing\n",
    "            cov[index_random,i] = var_missing\n",
    "\n",
    "    y = y.reshape((n,1))\n",
    "\n",
    "    return X,y,cov\n",
    "\n",
    "# 確率的\n",
    "def regression_probabilistic_imputation(X,y,sigma):\n",
    "    # 欠損箇所を取得\n",
    "    n = y.shape[0]\n",
    "    missing_index = np.where(np.isnan(y))[0]\n",
    "\n",
    "    # missing_index番目の以外のX,yを取得\n",
    "    X_delete = np.delete(X, missing_index, 0)\n",
    "    y_delete = np.delete(y, missing_index, 0).reshape(-1,1)\n",
    "\n",
    "    cov = np.identity(n)\n",
    "\n",
    "    # 回帰係数の推定\n",
    "    beta_hat = np.linalg.inv(X_delete.T @ X_delete) @ X_delete.T @ y_delete\n",
    "\n",
    "    data_list = list(range(n))\n",
    "\n",
    "    # 各欠損箇所に対して\n",
    "    for index_random in missing_index:\n",
    "\n",
    "        # 欠損しているデータを取得\n",
    "        X_missing = X[index_random]\n",
    "\n",
    "        # beta_hatにより欠損していた値を補完\n",
    "        rng = np.random.default_rng()\n",
    "        noise = rng.standard_normal()\n",
    "\n",
    "        y_new = X_missing @ beta_hat + noise\n",
    "\n",
    "        # 欠損箇所の補完\n",
    "        y[index_random] = y_new\n",
    "\n",
    "        # 分散の計算\n",
    "        # 列ごとに分散，共分散を計算しているイメージ\n",
    "        for i in data_list:\n",
    "            # データの抽出\n",
    "            each_x = X[i]\n",
    "\n",
    "            if i == index_random or i in missing_index:\n",
    "                var_missing = sigma**2 * each_x @ np.linalg.inv(X_delete.T @ X_delete) @ X_missing.T + 1\n",
    "                cov[i,index_random] = var_missing\n",
    "                cov[index_random,i] = var_missing\n",
    "            \n",
    "            else:\n",
    "                var_missing = sigma**2 * each_x @ np.linalg.inv(X_delete.T @ X_delete) @ X_missing.T\n",
    "                cov[i,index_random] = var_missing\n",
    "                cov[index_random,i] = var_missing\n",
    "\n",
    "            #var_missing = (sigma * each_x.T @ np.linalg.inv(X_delete.T @ X_delete) @ X_missing)[0,0]\n",
    "\n",
    "    y = y.reshape((n,1))\n",
    "\n",
    "    return X,y,cov"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
